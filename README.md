# Building-an-ETL-Pipeline-using-PySpark
This project implements a scalable ETL pipeline using PySpark to process a global temperature dataset (1961â€“2022). It transforms wide-format data into a normalized long-format schema, optimized for analytics and machine learning, while leveraging distributed computing for efficient big data processing.
